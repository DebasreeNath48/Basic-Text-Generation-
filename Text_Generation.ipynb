{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMoPmcm3h/rHHJ4CwZfo9qg"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "msUd2MdKzmKk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_df = pd.read_csv(\"fake_or_real_news.csv\")"
      ],
      "metadata": {
        "id": "D73vxMS_3bXO"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = list(text_df.text.values)\n",
        "joined_text = \" \".join(text)"
      ],
      "metadata": {
        "id": "FQD8UUah4i8y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "partial_text = joined_text[:10000]"
      ],
      "metadata": {
        "id": "PTWaptYC4s0k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "tokens = tokenizer.tokenize(partial_text.lower())"
      ],
      "metadata": {
        "id": "fhGRYHUS45th"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_tokens = np.unique(tokens)\n",
        "unique_token_index = {token: idx for idx, token in enumerate(unique_tokens)}"
      ],
      "metadata": {
        "id": "9bwpa4HD5Sxy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_words = 10\n",
        "input_words = []\n",
        "next_words = []\n",
        "\n",
        "for i in range(len(tokens) - n_words):\n",
        "  input_words.append(tokens[i:i+n_words])\n",
        "  next_words.append(tokens[i+n_words])"
      ],
      "metadata": {
        "id": "7h7zFJC75wDK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.zeros((len(input_words), n_words, len(unique_tokens)), dtype=bool)\n",
        "y = np.zeros((len(next_words), len(unique_tokens)), dtype=bool)"
      ],
      "metadata": {
        "id": "13KxSaS562Dw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,words in enumerate(input_words):\n",
        "  for j, word in enumerate(words):\n",
        "    x[i, j, unique_token_index[word]] = 1\n",
        "  y[i, unique_token_index[next_words[i]]] = 1"
      ],
      "metadata": {
        "id": "U5WhT_QJ5wAq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(n_words,len(unique_tokens)), return_sequences=True))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(len(unique_tokens)))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "YCGxWkbCAAWE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=RMSprop(learning_rate=0.01), metrics=[\"accuracy\"])\n",
        "model.fit(x,y,batch_size=128, epochs=30, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr0xJkqzBIl9",
        "outputId": "7880acfb-14b9-49e7-d13a-9eed20148f94"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "14/14 [==============================] - 6s 154ms/step - loss: 6.1782 - accuracy: 0.0395\n",
            "Epoch 2/30\n",
            "14/14 [==============================] - 2s 110ms/step - loss: 5.8491 - accuracy: 0.0601\n",
            "Epoch 3/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 5.8025 - accuracy: 0.0618\n",
            "Epoch 4/30\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 5.7671 - accuracy: 0.0618\n",
            "Epoch 5/30\n",
            "14/14 [==============================] - 1s 90ms/step - loss: 5.7396 - accuracy: 0.0618\n",
            "Epoch 6/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 5.6796 - accuracy: 0.0618\n",
            "Epoch 7/30\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 5.6321 - accuracy: 0.0595\n",
            "Epoch 8/30\n",
            "14/14 [==============================] - 1s 101ms/step - loss: 5.5245 - accuracy: 0.0675\n",
            "Epoch 9/30\n",
            "14/14 [==============================] - 2s 103ms/step - loss: 5.3410 - accuracy: 0.0841\n",
            "Epoch 10/30\n",
            "14/14 [==============================] - 2s 149ms/step - loss: 5.1791 - accuracy: 0.0835\n",
            "Epoch 11/30\n",
            "14/14 [==============================] - 2s 153ms/step - loss: 4.9030 - accuracy: 0.1007\n",
            "Epoch 12/30\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 4.7000 - accuracy: 0.0967\n",
            "Epoch 13/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 4.3906 - accuracy: 0.1219\n",
            "Epoch 14/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 4.2065 - accuracy: 0.1384\n",
            "Epoch 15/30\n",
            "14/14 [==============================] - 1s 86ms/step - loss: 3.7452 - accuracy: 0.1762\n",
            "Epoch 16/30\n",
            "14/14 [==============================] - 1s 87ms/step - loss: 3.4219 - accuracy: 0.2100\n",
            "Epoch 17/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 3.1296 - accuracy: 0.2494\n",
            "Epoch 18/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 2.7054 - accuracy: 0.3450\n",
            "Epoch 19/30\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 2.3901 - accuracy: 0.4142\n",
            "Epoch 20/30\n",
            "14/14 [==============================] - 2s 142ms/step - loss: 2.0163 - accuracy: 0.5257\n",
            "Epoch 21/30\n",
            "14/14 [==============================] - 2s 148ms/step - loss: 1.7570 - accuracy: 0.5995\n",
            "Epoch 22/30\n",
            "14/14 [==============================] - 1s 95ms/step - loss: 1.4039 - accuracy: 0.7082\n",
            "Epoch 23/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 1.1061 - accuracy: 0.7969\n",
            "Epoch 24/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.8934 - accuracy: 0.8427\n",
            "Epoch 25/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.6692 - accuracy: 0.9045\n",
            "Epoch 26/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.5229 - accuracy: 0.9416\n",
            "Epoch 27/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.3868 - accuracy: 0.9622\n",
            "Epoch 28/30\n",
            "14/14 [==============================] - 1s 88ms/step - loss: 0.2649 - accuracy: 0.9760\n",
            "Epoch 29/30\n",
            "14/14 [==============================] - 1s 89ms/step - loss: 0.2320 - accuracy: 0.9840\n",
            "Epoch 30/30\n",
            "14/14 [==============================] - 2s 138ms/step - loss: 0.1642 - accuracy: 0.9886\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b335e1ea470>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Textmodel.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrGT4w3XCJ9z",
        "outputId": "c822b792-d59b-4f2b-eeb9-988fa493f412"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(\"Textmodel.h5\")"
      ],
      "metadata": {
        "id": "JKLJda8QCJ7G"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_word(input_text, n_best):\n",
        "  input_text = input_text.lower()\n",
        "  x = np.zeros((1, n_words, len(unique_tokens)))\n",
        "  for i,word in enumerate(input_text.split()):\n",
        "    x[0, i, unique_token_index[word]] = 1\n",
        "\n",
        "  predictions = model.predict(x)[0]\n",
        "  return np.argpartition(predictions, -n_best)[-n_best:]"
      ],
      "metadata": {
        "id": "w6DiZODsEGaR"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "possible = predict_next_word(\"She has to go now and\",5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Y5e71XwFJAr",
        "outputId": "ff4a237b-b14a-4273-8f58-dfa3335d4d76"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print([unique_tokens[idx] for idx in possible])"
      ],
      "metadata": {
        "id": "IWsj5gOVFpOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(input_text, text_length, creativity=3):\n",
        "  word_sequence = input_text.split()\n",
        "  current = 0\n",
        "  for _ in range(text_length):\n",
        "    sub_sequence = \" \".join(tokenizer.tokenize(\" \".join(word_sequence).lower())[current : current+n_words])\n",
        "    try:\n",
        "      choice = unique_tokens[random.choice(predict_next_word(sub_sequence, creativity))]\n",
        "    except:\n",
        "      choice = random.choice(unique_tokens)\n",
        "    word_sequence.append(choice)\n",
        "    current += 1\n",
        "  return \" \".join(word_sequence)"
      ],
      "metadata": {
        "id": "ggsyoR3zF5jF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(\"She has to go now and\", 100, 5)"
      ],
      "metadata": {
        "id": "os6a5kNmIpL9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}